{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时间戳转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Convert human-readable date to Unix timestamp\n",
    "def date_to_timestamp(year, month, day):\n",
    "    dt = datetime(year, month, day)\n",
    "    timestamp = dt.timestamp()\n",
    "    return int(timestamp)\n",
    "\n",
    "# Convert Unix timestamp to human-readable date\n",
    "def timestamp_to_date(timestamp):\n",
    "    dt = datetime.fromtimestamp(timestamp)\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "    return year, month, day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一组句子中相同的最长连续序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试（已弃用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common substrings and their counts:\n",
      "天下: 2\n",
      "天下第: 2\n",
      "下第: 2\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "stopwords_path = r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\addition\\stopwords_cn.txt\"\n",
    "    \n",
    "def find_common_substrings(sentences,stopwords: str='',filter:int = 0,min_length:int = 2,max_length:int = 5):\n",
    "    if stopwords != '':\n",
    "    # 导入停用词列表\n",
    "        with open(stopwords, 'r', encoding='utf-8') as f:\n",
    "            stopwords = f.read().splitlines()\n",
    "    # 创建一个字典用于存储相同连续词语的出现次数\n",
    "    common_substrings_count = defaultdict(int)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = []\n",
    "        for char in sentence:\n",
    "            words.append(char)\n",
    "        n = len(words)\n",
    "\n",
    "        # 遍历每个词语组成的子串，计算其出现次数\n",
    "        for i in range(n):\n",
    "            for j in range(i + min_length, min(n, i + max_length + 1)):\n",
    "                if j - i > max_length:\n",
    "                    break\n",
    "                for k in words[i:j]:\n",
    "                    if k in stopwords:\n",
    "                        continue\n",
    "                substring = ''.join(words[i:j])\n",
    "                if substring not in stopwords:\n",
    "                    common_substrings_count[substring] += 1\n",
    "    if filter == 0:\n",
    "        return common_substrings_count\n",
    "    # 从字典中筛选出出现次数大于1的词语或词组\n",
    "    common_substrings = {substring: count for substring, count in common_substrings_count.items() if count >= filter}\n",
    "\n",
    "    return common_substrings\n",
    "\n",
    "# 示例\n",
    "sentences = [\n",
    "    \"我是谁\",\n",
    "    \"你说我是谁\",\n",
    "    \"我是天下第一\",\n",
    "    \"天下第一是谁\"\n",
    "]\n",
    "\n",
    "common_substrings = find_common_substrings(sentences, stopwords_path, 2, 2, 3)\n",
    "print(\"Common substrings and their counts:\")\n",
    "for substring, count in common_substrings.items():\n",
    "    print(f\"{substring}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "stopwords_path = r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\addition\\stopwords_cn.txt\"\n",
    "\n",
    "# 加载停用词列表\n",
    "with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "def find_common_substrings(sentences, filter=0, min_length=2, max_length=5):\n",
    "    # 创建一个字典用于存储相同连续词语的出现次数\n",
    "    common_substrings_count = defaultdict(int)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = list(sentence)  # 将字符串转换为字符列表\n",
    "        n = len(words)\n",
    "\n",
    "        # 遍历每个词语组成的子串，计算其出现次数\n",
    "        for i in range(n):\n",
    "            for j in range(i + min_length, min(n, i + max_length + 1)):\n",
    "                if j - i > max_length:\n",
    "                    break\n",
    "                if any(char in stopwords for char in words[i:j]):  # 如果有字符在停用词中，跳出当前循环\n",
    "                    continue\n",
    "                substring = ''.join(words[i:j])\n",
    "                common_substrings_count[substring] += 1\n",
    "\n",
    "    if filter == 0:\n",
    "        return common_substrings_count\n",
    "    # 从字典中筛选出出现次数大于等于filter的词语或词组\n",
    "    common_substrings = {substring: count for substring, count in common_substrings_count.items() if count >= filter}\n",
    "\n",
    "    return common_substrings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多线程（最终版本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsequences of size 3: [('我是天', 0, 3), ('是天下', 1, 4), ('天下第', 2, 5), ('下第一', 3, 6)]\n"
     ]
    }
   ],
   "source": [
    "##滑动窗口\n",
    "def find_subsequences(sentence, window_size):\n",
    "    subsequences = []\n",
    "\n",
    "    for i in range(len(sentence) - window_size + 1):\n",
    "        window = sentence[i:i + window_size]\n",
    "        subsequences.append((window, i, i + window_size ))\n",
    "\n",
    "    return subsequences\n",
    "\n",
    "# 示例\n",
    "sentence = \"我是天下第一\"\n",
    "window_size = 3\n",
    "subsequences = find_subsequences(sentence, window_size)\n",
    "print(f\"Subsequences of size {window_size}: {subsequences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'喜欢吃苹果': 4, '喜欢橙子': 3}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "stopwords_path = r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\addition\\stopwords_cn.txt\"\n",
    "\n",
    "# 加载停用词列表\n",
    "with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "    stopwords = set(f.read().splitlines())\n",
    "\n",
    "def judge_max_common_sentence(location, max_common_substrings_location):\n",
    "    if max_common_substrings_location == []:\n",
    "        return True\n",
    "    for k in max_common_substrings_location:\n",
    "        if location[0] >= k[0] and location[1] <= k[1]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def process_sentence(sentence, min_length, max_length, common_substrings_count):\n",
    "    sentence = sentence.replace('\\n', '')\n",
    "    max_common_substrings_location = []\n",
    "    max_size = min(max_length+1,len(sentence)+1)\n",
    "    for i in range(min_length, max_size):\n",
    "        for j in find_subsequences(sentence, max_size-i+min_length):\n",
    "            substring = j[0]\n",
    "            if any(char in stopwords for char in substring) or substring in stopwords:\n",
    "                continue\n",
    "            if substring not in common_substrings_count.keys():\n",
    "                common_substrings_count[substring] = 1\n",
    "                max_common_substrings_location.append((j[1], j[2]))\n",
    "            elif judge_max_common_sentence(j[1:], max_common_substrings_location):\n",
    "                common_substrings_count[substring] += 1\n",
    "                max_common_substrings_location.append((j[1], j[2]))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "def find_common_substrings(sentences, filter=0, min_length=2, max_length=50):\n",
    "    common_substrings_count = defaultdict(int)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(process_sentence, sentence, min_length, max_length, common_substrings_count) for sentence in sentences]\n",
    "        concurrent.futures.wait(futures)\n",
    "\n",
    "    if filter == 0:\n",
    "        return common_substrings_count\n",
    "\n",
    "    common_substrings = {substring: count for substring, count in common_substrings_count.items() if count >= filter}\n",
    "    return common_substrings\n",
    "\n",
    "# 测试\n",
    "sentences = [\"我喜欢吃苹果和橙子\", \"她也喜欢吃苹果但更喜欢橙子\", \"他不喜欢吃苹果也不喜欢橙子\", \"我喜欢吃苹果也喜欢橙子\"]\n",
    "result = find_common_substrings(sentences, filter=2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按时间排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all.csv\")\n",
    "\n",
    "# 按\"ctime\"列的值从小到大进行排序\n",
    "df_sorted = df.sort_values(by=\"ctime\")\n",
    "\n",
    "# 将排序后的结果写入新的CSV文件\n",
    "df_sorted.to_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按点赞数排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all.csv\")\n",
    "\n",
    "# 按\"like\"列的值从大到小进行排序\n",
    "df_sorted = df.sort_values(by=\"like\", ascending=False)\n",
    "\n",
    "# 将排序后的结果写入新的CSV文件\n",
    "df_sorted.to_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted_like.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取CSV文件,并取出前10000行\n",
    "df = pd.read_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted_like.csv\", nrows=10000)\n",
    "\n",
    "# 将前10000行的数据写入新的CSV文件\n",
    "df.to_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted_like_10000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读取CSV文件,并取出前10000行\n",
    "df = pd.read_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted_like.csv\", nrows=100)\n",
    "\n",
    "# 将前10000行的数据写入新的CSV文件\n",
    "df.to_csv(r\"D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted_like_100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一组句子中相同的最长连续序列——>批量处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "com_sentences = []\n",
    "# 读取csv文件\n",
    "with open(r'D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        if int(row['ctime']) <= int(date_to_timestamp(2024, 2, 3)):\n",
    "            com_sentences.append(row['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime(2024, 2, 2)\n",
    "end_date = datetime(2024, 3, 8)\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    current_date += timedelta(days=1)\n",
    "    year, month, day= current_date.year, current_date.month, current_date.day\n",
    "    com_sentences = []\n",
    "    yesterday_data = current_date-timedelta(days=1)\n",
    "\n",
    "    # 读取csv文件\n",
    "    with open(r'D:\\毕业论文\\bilibili_data\\bilibili_data\\data\\results\\merged_data_with_time_all_sorted.csv', 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            if int(row['ctime']) <= int(date_to_timestamp(year, month, day)) and int(row['ctime']) >= int(date_to_timestamp(yesterday_data.year, yesterday_data.month, yesterday_data.day)):\n",
    "                com_sentences.append(row['content'])\n",
    "    com_dict =  find_common_substrings(com_sentences, 2, 2, 50)\n",
    "    # 将com_dict按照value值进行排序并写入csv文件\n",
    "    com_dict_sorted = sorted(com_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    com_data_sorted = pd.DataFrame(com_dict_sorted, columns=['common_substrings', 'count'])\n",
    "    file_path = \"D:/毕业论文/bilibili_data/bilibili_data/data/results/common_sentence/%s-%s-%s.csv\" % (year, month, day-1)\n",
    "    com_data_sorted.to_csv(file_path,mode='w', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
